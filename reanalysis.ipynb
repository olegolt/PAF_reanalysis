{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-analysis for \"A novel cortical biomarker signature predicts individual pain sensitivity\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import os\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set your basepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base path\n",
    "basepath = \"/home/ole/projects/PAF_reanalysis\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main analysis\n",
    "\n",
    "This does the following: \\\n",
    "\\\n",
    "(1) loads in complete dataset with PAF, CME and class for all subjects. \\\n",
    "(2) defines models and its parameter space \\\n",
    "(3) splits data in independent training and test set \\\n",
    "(4) uses gridsearch crossvalidation in training data to fit model \\\n",
    "(5) uses trained models to predict data of test set \\\n",
    "(6) reports accuracy and AUC for both, training and test set  \\\n",
    "\n",
    "This is repeatedly done to avoid an over/underestimation of the final metrics due to the relatively low sample size for a machine learning pipeline.\n",
    "\n",
    "Number of repetitions is set by parameter repetitions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set number of repetitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "repetitions = 20"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running analysis with seed 3548...\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Running analysis with seed 4090...\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Running analysis with seed 3925...\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Running analysis with seed 3545...\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Running analysis with seed 4442...\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Running analysis with seed 888...\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Running analysis with seed 5301...\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Running analysis with seed 7786...\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Running analysis with seed 7453...\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Running analysis with seed 2887...\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Running analysis with seed 325...\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Running analysis with seed 519...\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Running analysis with seed 8589...\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Running analysis with seed 2298...\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Running analysis with seed 6342...\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Running analysis with seed 1306...\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Running analysis with seed 9480...\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Running analysis with seed 6542...\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Running analysis with seed 4727...\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Running analysis with seed 2302...\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Analysis complete. Results saved.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "paf_file = os.path.join(basepath, \"data/PAF_all.xlsx\")\n",
    "cme_file = os.path.join(basepath, \"data/map_volume_all.xlsx\")\n",
    "class_file = os.path.join(basepath, \"data/class_IDs_all.xlsx\")\n",
    "\n",
    "df_paf = pd.read_excel(paf_file)\n",
    "df_cme = pd.read_excel(cme_file)\n",
    "df_class = pd.read_excel(class_file)\n",
    "\n",
    "# Calculate CME values\n",
    "df_cme[\"CME\"] = (df_cme.Volume_Day5 - df_cme.Volume_Day0).apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Merge data on ID\n",
    "data = df_class.merge(df_paf, on=\"ID\", how=\"inner\").merge(df_cme[[\"ID\", \"CME\"]], on=\"ID\", how=\"inner\")\n",
    "\n",
    "# Define predictors and target\n",
    "X = data[[\"sensorimotor_paf\", \"CME\"]]\n",
    "y = data[\"class\"]\n",
    "\n",
    "# Models and hyperparameters\n",
    "models_and_params = {\n",
    "    \"LogisticRegression\": (\n",
    "        LogisticRegression(),\n",
    "        {\n",
    "            'model__C': np.logspace(-3, 3, 30),\n",
    "            'model__solver': ['newton-cg', 'lbfgs'],\n",
    "            'model__max_iter': [200, 400, 2000, 5000]\n",
    "        }\n",
    "    ),\n",
    "    \"RandomForest\": (\n",
    "        RandomForestClassifier(),\n",
    "        {\n",
    "            'model__n_estimators': [300, 500, 1000],\n",
    "            'model__max_depth': [None, 5, 10],\n",
    "            'model__min_samples_split': [2, 5, 10],\n",
    "            'model__bootstrap': [True, False]\n",
    "        }\n",
    "    ),\n",
    "    \"GradientBoosting\": (\n",
    "        GradientBoostingClassifier(),\n",
    "        {\n",
    "            'model__learning_rate': [0.01, 0.1, 0.5],\n",
    "            'model__max_depth': [None, 2, 5],\n",
    "            'model__min_samples_split': [2, 5, 10],\n",
    "            'model__n_estimators': [100, 200]\n",
    "        }\n",
    "    ),\n",
    "    \"SVC\": (\n",
    "        SVC(probability=True),\n",
    "        {\n",
    "            'model__C': [0.01, 0.1, 1, 10],\n",
    "            'model__gamma': ['scale', 'auto']\n",
    "        }\n",
    "    ),\n",
    "    \"MLPClassifier\": (\n",
    "        MLPClassifier(),\n",
    "        {\n",
    "            'model__alpha': [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "            'model__hidden_layer_sizes': [(100,), (100, 100), (100, 100, 100)],\n",
    "            'model__max_iter': [5000]\n",
    "        }\n",
    "    )\n",
    "}\n",
    "\n",
    "# Function to perform analysis\n",
    "def run_analysis(random_seeds, n_runs):\n",
    "    results = []\n",
    "\n",
    "    for seed in random_seeds:\n",
    "        print(f\"Running analysis with seed {seed}...\")\n",
    "\n",
    "        # Shuffle data\n",
    "        X_shuffled, y_shuffled = shuffle(X, y, random_state=seed)\n",
    "\n",
    "        # Split data into training and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_shuffled, y_shuffled, test_size=0.35, random_state=seed)\n",
    "\n",
    "        for model_name, (model, param_grid) in models_and_params.items():\n",
    "\n",
    "            # Create pipeline\n",
    "            pipeline = Pipeline([\n",
    "                (\"imputer\", IterativeImputer(max_iter=100, random_state=seed)),\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"model\", model)\n",
    "            ])\n",
    "\n",
    "            # Perform grid search\n",
    "            search = GridSearchCV(\n",
    "                pipeline, param_grid=param_grid,\n",
    "                cv=5, scoring=\"accuracy\", verbose=1, n_jobs=-1\n",
    "            )\n",
    "            search.fit(X_train, y_train)\n",
    "\n",
    "            # Get the best model\n",
    "            best_model = search.best_estimator_\n",
    "\n",
    "            # Evaluate the model on training and test sets\n",
    "            for dataset, X_eval, y_eval, label in zip(\n",
    "                [\"train\", \"test\"],\n",
    "                [X_train, X_test],\n",
    "                [y_train, y_test],\n",
    "                [\"Training\", \"Test\"]\n",
    "            ):\n",
    "                y_pred = best_model.predict(X_eval)\n",
    "                y_pred_proba = best_model.predict_proba(X_eval)[:, 1]\n",
    "                accuracy = accuracy_score(y_eval, y_pred)\n",
    "                auc = roc_auc_score(y_eval, y_pred_proba)\n",
    "                results.append({\n",
    "                    \"Seed\": seed,\n",
    "                    \"Model\": model_name,\n",
    "                    \"Dataset\": label,\n",
    "                    \"Accuracy\": accuracy,\n",
    "                    \"AUC\": auc\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run analysis\n",
    "random_seeds = np.random.randint(0, 10000, size=repetitions)\n",
    "n_runs = repetitions\n",
    "results_df = run_analysis(random_seeds, n_runs=n_runs)\n",
    "\n",
    "# Aggregate results\n",
    "summary = results_df.groupby([\"Model\", \"Dataset\"]).mean()[[\"Accuracy\", \"AUC\"]].reset_index()\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv(os.path.join(basepath, \"results/results_all_runs.csv\"), index=False)\n",
    "summary.to_csv(os.path.join(basepath, \"results/summary_results.csv\"), index=False)\n",
    "\n",
    "print(\"Analysis complete. Results saved.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create plots for accuracy and AUC for all models \n",
    "\\\n",
    "Plot will only display the average for both metrics across all repetitions of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Accuracy plot as SVG: /home/ole/projects/PAF/figures/Accuracy_by_Model.svg\n",
      "Saved AUC plot as SVG: /home/ole/projects/PAF/figures/AUC_by_Model.svg\n"
     ]
    }
   ],
   "source": [
    "# Define the order of the Dataset categories\n",
    "hue_order = [\"Training\", \"Test\"]\n",
    "\n",
    "# Melt the DataFrame for easier plotting\n",
    "plot_df = summary.melt(id_vars=[\"Model\", \"Dataset\"], value_vars=[\"Accuracy\", \"AUC\"], \n",
    "                       var_name=\"Metric\", value_name=\"Score\")\n",
    "\n",
    "# Create the bar plot for Accuracy and AUC\n",
    "for metric in [\"Accuracy\", \"AUC\"]:\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.barplot(\n",
    "        data=plot_df[plot_df[\"Metric\"] == metric],\n",
    "        x=\"Score\",\n",
    "        y=\"Model\",\n",
    "        hue=\"Dataset\",\n",
    "        hue_order=hue_order,  # Ensure Training is always left and Test is right\n",
    "        palette={\"Training\": \"#9fc8c8\", \"Test\": \"#298c8c\"}  # Adjust colors\n",
    "    )\n",
    "\n",
    "    # Add values on bars\n",
    "    for container in plt.gca().containers:\n",
    "        labels = [f\"{v.get_width():.2f}\" for v in container]\n",
    "        plt.gca().bar_label(container, labels=labels, label_type='edge', fontsize=14)\n",
    "\n",
    "    # Add title and labels\n",
    "    plt.title(f\"{metric} by Model\", fontsize=20, fontweight=\"bold\")\n",
    "    plt.xlabel(metric, fontsize=16)\n",
    "    plt.ylabel(\"Model\", fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.legend(title=\"Dataset\", fontsize=14, title_fontsize=16, loc=\"lower right\")\n",
    "\n",
    "    # Remove grid lines\n",
    "    plt.gca().grid(False)\n",
    "    plt.gca().spines[\"left\"].set_linewidth(0.5)\n",
    "    plt.gca().spines[\"bottom\"].set_linewidth(0.5)\n",
    "\n",
    "    # Save the figure as an SVG\n",
    "    filename = os.path.join(basepath, f\"figures/{metric}_by_Model.svg\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, format=\"svg\")\n",
    "    plt.close()  # Close the plot to avoid overlap\n",
    "\n",
    "    print(f\"Saved {metric} plot as SVG: {filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
